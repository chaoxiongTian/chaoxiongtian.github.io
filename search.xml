<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[tensorflow-构建CNN识别自己的数据（类似于MNSIT）]]></title>
    <url>%2F2017%2F12%2F05%2Ftensorflow-%E6%9E%84%E5%BB%BACNN%E8%AF%86%E5%88%AB%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%88%E7%B1%BB%E4%BC%BC%E4%BA%8EMNSIT%EF%BC%89%2F</url>
    <content type="text"><![CDATA[转载请注明出处http://www.jianshu.com/p/75a8eb564de7在学习了通过构建CNN来识别MNIST之后，我们都大概理解了tensorflow的构建过程，那么怎么才用CNN来识别自己的数据呢？想想都有意思，那就请认真的看下面的文章 说明： 图片数据是通过代码自己生成的不用下载，下面先讲的就是怎么生成图片，生成的时候需要用到 字体文件和cv2库 我在下文中都给出了地址和安装方式。 生成了图片之后，训练的时候是image是从文件夹读的，label是从文本读的，如果想改，完全可以按照规则改成自己的数据，不过记得再完成卷积之后的全连接层的时候一定要改按照图片的大小改输入。 有什么问题欢迎留言。 解释基本都在代码中，基本都有注释，欢迎留言 完整代码和image样本：如果把data下面的训练图片和测试图片都下载了的话，可以不同再生成图片，可直接训练，再研究如何调用图片即可https://coding.net/u/centaur/p/Share/git/tree/master/custom_image_tutorials ##生成数据先看一下生成的数据如下图 这里的数据类似于MNSIT的形式，只含有十个数字。 MNIST是手写的数字，这里为了模仿这个效果对图片做了一定的扭曲和旋转下面做一个对比 因为文件中多个地方都用到了相对于代码存储位置，这里大家先看一下我的目录结构 data下面的image分别是测试和训练的样本 路径是&quot;data/image/train/&quot;和&quot;data/image/train/&quot; 下面是两个文本 分别是训练和测试的label，文本中9#8#1#8#5#7#7#1#4#0#3#2#7#8#9#8#5#3#1#8#4#1#1#5#2#7#9#5#2#7#0#1#7......每两个标签之间通过#连接，图片是按照0,1,2…的顺序命名的，这样正好把image和label对应了起来，在训练的时候容易取。 DroidSansMono.ttf是生成图片中字的字体，可做更改，代码中也要记着更改。 get_text.py是生成两个label文本的代码，其中可指定生成训练和测试样本的数量 read_text_generate_image.py是通过读label文本然后生成对应的图片。再生成图片的时候一定要记着把字体放在data/目录下面下载地址 train.py是训练的代码 ####生成测试样本和训练样本的label。生成label的代码比较简单就不做赘述12345678910111213141516171819202122232425262728293031323334353637383940414243import randomimport osnumber = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']path_dir = "data/"# 不存在直接创建if not os.path.exists(path_dir): os.makedirs(path_dir)# 随机的返回一个字符，这里不只限于生成一个字符（后期扩展性）def random_number_text(char_set=number, code_size=1): code_text = [] for each in range(code_size): c = random.choice(char_set) code_text.append(c) return code_textdef write_labels(size, name): code_list = [] for each in range(size): number_list = random_number_text() code = ''.join(number_list) # 用引号中的东西去连接list的两个条目 code_list.append(code) code_text = '#'.join(code_list) print(code_text) f = open(path_dir + name, 'w') f.write(code_text) f.close()def main(): # 可指定大小 trian_size = 5000 test_size = 1000 train_label_name = "code_train_text.txt" test_label_name = "code_test_text.txt" write_labels(trian_size, train_label_name) write_labels(test_size, test_label_name)if __name__ == '__main__': main() ####根据样本生成image再生成图片的时候一定要记着把字体放在data/目录下面下载地址 有人安装opencv 请用pip install opencv-python这个指令 如果你的电脑是Windows还可能报下面这个错误:1234import cv2Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;ImportError: DLL load failed: 找不到指定的模块。 不要惊慌，这是因为opencv需要依赖MSVCP140.dll 这个C++类库，而python 3.5 以上的版本不包括这个类库，你的系统正好是windows 家庭版啥的，也没有这个类库，因此去下载 不要惊慌 解决方案生成图片需要用到cv2 这个库 记着安装pip install opencv-pythonread_text_generate_image.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103import osimport randomfrom PIL import Image, ImageDraw, ImageFontimport numpy as npimport cv2# 超参数 需要的文件先创建image_path_train = "data/image/train/"if not os.path.exists(image_path_train): os.makedirs(image_path_train)image_path_test = "data/image/test/"if not os.path.exists(image_path_test): os.makedirs(image_path_test)# 指定字体DEFAULT_FONTS = "data/DroidSansMono.ttf"# 生成图片的大小WIDHT = 28HEIGHT = 28# 把label中的内容返回list调用def get_content_from_file(label_name): content = open("data/" + label_name, "r", encoding="utf-8") code_text = content.read() return code_text.split("#")# 用opencv 转为灰度 这里需要用到cv2def convert2gray(img): if len(img.shape) &gt; 2: gray = np.mean(img, -1) # 上面的转法较快，正规转法如下 # r, g, b = img[:,:,0], img[:,:,1], img[:,:,2] # gray = 0.2989 * r + 0.5870 * g + 0.1140 * b return gray else: return img# 再目录dir_path下生成 名字为i.jpg 内容为c的图片def generate_image(i, c, dir_path): path = dir_path + str(i) + ".jpg" print(path) color = (0, 0, 0) # 字体颜色 background = (255, 255, 255) # 背景颜色 print(str(i) + "要存的字符是" + c) # 创建函数 image = create_image_one_char(c, color, background) image = convert2gray(np.array(image)) # 转为灰度 cv2.imwrite(path, image)# 用cv2存起来# 更加内容c 生成扭曲和旋转的imagedef create_image_one_char(c, color, background): # 自定义字体 font = ImageFont.truetype(DEFAULT_FONTS, 30) im = Image.new('RGBA', (WIDHT, HEIGHT), background) drawAvatar = ImageDraw.Draw(im) w, h = im.size drawAvatar.text((4, -3), c, fill=color, font=font) # 在图片上写下内容 del drawAvatar # 释放对象 # 旋转 整个图片旋转 im = im.crop(im.getbbox()) im = im.rotate(random.uniform(-30, 30), Image.BILINEAR, expand=1) # 扭曲 # 随机生成 几个坐标 为了得到相对扭曲的四个角的坐标 dx = w * random.uniform(0.1, 0.4) dy = h * random.uniform(0.2, 0.5) x1 = int(random.uniform(-dx, dx)) y1 = int(random.uniform(-dy, dy)) x2 = int(random.uniform(-dx, dx)) y2 = int(random.uniform(-dy, dy)) w2 = w + abs(x1) + abs(x2) h2 = h + abs(y1) + abs(y2) data = ( x1, y1, -x1, h2 - y2, w2 + x2, h2 + y2, w2 - x2, -y1, ) im = im.resize((w2, h2)) # 变量data是一个8元组(x0,y0,x1,y1,x2,y2,x3,y3)，它包括源四边形的左 # 上，左下，右下和右上四个角。 通过四个角去拉扯一张图片 im = im.transform((WIDHT, HEIGHT), Image.QUAD, data) image = Image.new('RGB', (WIDHT, HEIGHT), background) # 把旋转乱了的图片贴在一个正规的图片上 image.paste(im, (0, 0), im) return image# 超参数train_label_name = "code_train_text.txt"test_label_name = "code_test_text.txt"# 根据label名和文件夹位置生成图片def write_image(label_name, dir_path): code_list = get_content_from_file(label_name) for each in range(len(code_list)): generate_image(each, code_list[each], dir_path)def main(): # 分别处理 训练样本和测试样本 write_image(train_label_name, image_path_train) write_image(test_label_name, image_path_test)if __name__ == '__main__': main() ###CNN训练转载请注明出处http://www.jianshu.com/p/75a8eb564de7 网络模型网络模型是一个两层的卷积和池化 加上两个全连接层123456789101112131415161718192021222324def code_cnn(): # 第一个卷积层 W_conv1 = weigth_variable([5, 5, 1, 32]) b_conv1 = weigth_variable([32]) h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # 28*28*32 h_pool1 = max_pool_2x2(h_conv1) # 14*14*32 # 第二个卷积层 W_conv2 = weigth_variable([5, 5, 32, 64]) b_conv2 = weigth_variable([64]) h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # 14*14*64 h_pool2 = max_pool_2x2(h_conv2) # 7*7*64 h_pool2 = tf.nn.dropout(h_pool2, keep_prob) # 三层全连接层 W_fc1 = weigth_variable([7 * 7 * 64, 1024]) b_fc1 = bias_varibale([1024]) # [n_samples, 7, 7, 64] -&gt;&gt; [n_samples, 7*7*64] h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64]) h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) # 防止过度拟合 # 第四层全连接层 W_fc2 = weigth_variable([1024, 10]) b_fc2 = bias_varibale([10]) prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2) return prediction 取数据训练既然把数据存成了图片那么就需要把图片读出来转成tensor 1. 把image和label从文件总读出来，都成相应的list方便操作。12345678910111213141516171819# 根据路径得到文本的内容def getStrContent(path): return open(path, 'r', encoding="utf-8").read()# 返回 训练样本路径的list 和 对应的标签用来以后训练def get_image_path_labels(IMAGE_PATH=IMAGE_PATH, LABEL_PATH=LABEL_PATH, IMAGE_MUMBER=IMAGE_MUMBER): image_path = IMAGE_PATH label_path = LABEL_PATH image_paths = [] for each in range(IMAGE_MUMBER): image_paths.append(image_path + str(each) + ".jpg") string = getStrContent(label_path) labels = string.split("#") return image_paths, labelsdef main(): # 得到训练样本路径list和标签的list image_paths, labels = get_image_path_labels() train_code_cnn(image_paths, labels) 2. 数据被放在了对应的list中那么就可对应的取数据，训练数据我们训练样本生成了5000个测试样本生成了1000个下面代码中的batch设置为了100 每次把100张图片存成一个tensor.所以我们需要对5000个数据进行迭代读取。生成一个batch1234567891011121314151617181920212223# 生成一个训练batch 把batch个image和lebel拼成两个tensor# 这里的each是一个迭代器 因为有5000个图片每次100个，所以是循环传入的0到49def get_next_batch(batch_size, each, images, labels): # image的tensor batch_x = np.zeros([batch_size, IMAGE_HEIGHT * IMAGE_WIDTH]) # label的tensor batch_y = np.zeros([batch_size, 10]) def get_text_and_image(i, each): image_num = each * batch_size + i label = labels[image_num] image_path = images[image_num] captcha_image = Image.open(image_path) #按照路径打开图片 captcha_image = np.array(captcha_image) return label, captcha_image # 按照 batch_size迭代 for i in range(batch_size): text, image = get_text_and_image(i, each) image = convert2gray(image)#转为灰度 batch_x[i, :] = image.flatten() / 255 # (image.flatten()-128)/128 mean为0 batch_y[i, :] = text2vec(text) return batch_x, batch_y 训练数据在训练的时候会进行测试，分别用测试数据集和训练数据集合进行测试一般来说训练数据要比测试数据好很多，不过我训练了一会发现两个差不多1234567891011121314151617181920212223for epoch in range(EPOCH): # 每个epoch for each in range(int(IMAGE_MUMBER / BATCH_SIZE)): batch_x, batch_y = get_next_batch(BATCH_SIZE, each, image_paths, labels) _, loss_ = sess.run([train_step, cross_entropy] , feed_dict=&#123;xs: batch_x, ys: batch_y, keep_prob: 0.5&#125;) print("epoch: %d iter: %d/%d loss: %f" % (epoch + 1, BATCH_SIZE * each, IMAGE_MUMBER, loss_)) # 测试样本计算准确率 # 这里还是按照训练的时候的方法，把image好label分别都成list # 然后统一转为tensor再通过测试函数进行测试。 test_iamge_path = "data/image/test/" test_labels_path = "data/code_test_text.txt" test_image_paths, test_labels = \ get_image_path_labels(test_iamge_path, test_labels_path, 200) batch_x_test, batch_y_test = \ get_random_batch(BATCH_SIZE, test_image_paths, test_labels,200) accuracy_test = compute_accuracy(batch_x_test, batch_y_test, sess) print("测试样本测试 epoch: %d acc: %f" % (epoch + 1, accuracy_test)) # 训练样本计算准确率 batch_x_test, batch_y_test = get_random_batch(BATCH_SIZE, image_paths, labels) accuracy = compute_accuracy(batch_x_test, batch_y_test, sess) print("训练样本测试 epoch: %d acc: %f" % (epoch + 1, accuracy)) 因为图片比较小，训练起来很快 再28个epoch的时候训练数据能达到100%，训练数据能达到99%123456789epoch: 28 iter: 4300/5000 loss: 0.070238epoch: 28 iter: 4400/5000 loss: 0.039228epoch: 28 iter: 4500/5000 loss: 0.039181epoch: 28 iter: 4600/5000 loss: 0.048799epoch: 28 iter: 4700/5000 loss: 0.165373epoch: 28 iter: 4800/5000 loss: 0.040288epoch: 28 iter: 4900/5000 loss: 0.061203测试样本 epoch: 28 acc: 0.990000训练样本 epoch: 28 acc: 1.000000 转载请注明出处http://www.jianshu.com/p/75a8eb564de7 到这里算是介绍完了，我把完整的代码贴在下面123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240import tensorflow as tfimport numpy as npfrom PIL import Imageimport randomIMAGE_MUMBER = 5000EPOCH = 200BATCH_SIZE = 100IMAGE_PATH = "data/image/train/"LABEL_PATH = "data/code_train_text.txt"# 计算weightdef weigth_variable(shape): # stddev : 正态分布的标准差 initial = tf.truncated_normal(shape, stddev=0.1) # 截断正态分布 return tf.Variable(initial)# 计算biasesdef bias_varibale(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial)# 计算卷积def conv2d(x, W): return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')# 定义池化def max_pool_2x2(x): return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')IMAGE_HEIGHT = 28IMAGE_WIDTH = 28CHAR_SET_LEN = 10xs = tf.placeholder(tf.float32, [None, IMAGE_HEIGHT * IMAGE_WIDTH])ys = tf.placeholder(tf.float32, [None, 10])keep_prob = tf.placeholder(tf.float32) # 防止过拟合x_image = tf.reshape(xs, [-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1])# 训练网络def code_cnn(): # 第一个卷积层 W_conv1 = weigth_variable([5, 5, 1, 32]) b_conv1 = weigth_variable([32]) h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # 28*28*32 h_pool1 = max_pool_2x2(h_conv1) # 14*14*32 # 第二个卷积层 W_conv2 = weigth_variable([5, 5, 32, 64]) b_conv2 = weigth_variable([64]) h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # 14*14*64 h_pool2 = max_pool_2x2(h_conv2) # 7*7*64 h_pool2 = tf.nn.dropout(h_pool2, keep_prob) # 三层全连接层 W_fc1 = weigth_variable([7 * 7 * 64, 1024]) b_fc1 = bias_varibale([1024]) # [n_samples, 7, 7, 64] -&gt;&gt; [n_samples, 7*7*64] h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64]) h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) # 防止过度拟合 # 第四层全连接层 W_fc2 = weigth_variable([1024, 10]) b_fc2 = bias_varibale([10]) prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2) return predictiondef convert2gray(img): if len(img.shape) &gt; 2: gray = np.mean(img, -1) # 上面的转法较快，正规转法如下 # r, g, b = img[:,:,0], img[:,:,1], img[:,:,2] # gray = 0.2989 * r + 0.5870 * g + 0.1140 * b return gray else: return img# 文本转向量def text2vec(text): text_len = len(text) vector = np.zeros(1 * CHAR_SET_LEN) def char2pos(c): if c == '_': k = 62 return k k = ord(c) - 48 if k &gt; 9: k = ord(c) - 55 if k &gt; 35: k = ord(c) - 61 if k &gt; 61: raise ValueError('No Map') return k for i, c in enumerate(text): idx = i * CHAR_SET_LEN + char2pos(c) vector[idx] = 1 return vector# 向量转回文本def vec2text(vec): char_pos = vec.nonzero()[0] text = [] for i, c in enumerate(char_pos): char_at_pos = i # c/63 char_idx = c % CHAR_SET_LEN if char_idx &lt; 10: char_code = char_idx + ord('0') elif char_idx &lt; 36: char_code = char_idx - 10 + ord('A') elif char_idx &lt; 62: char_code = char_idx - 36 + ord('a') elif char_idx == 62: char_code = ord('_') else: raise ValueError('error') text.append(chr(char_code)) return "".join(text)# 生成一个训练batchdef get_next_batch(batch_size, each, images, labels): batch_x = np.zeros([batch_size, IMAGE_HEIGHT * IMAGE_WIDTH]) batch_y = np.zeros([batch_size, 10]) def get_text_and_image(i, each): image_num = each * batch_size + i label = labels[image_num] image_path = images[image_num] captcha_image = Image.open(image_path) captcha_image = np.array(captcha_image) return label, captcha_image for i in range(batch_size): text, image = get_text_and_image(i, each) image = convert2gray(image) batch_x[i, :] = image.flatten() / 255 # (image.flatten()-128)/128 mean为0 batch_y[i, :] = text2vec(text) return batch_x, batch_y# 随机生成一个训练batchdef get_random_batch(batch_size, images, labels,IMAGE_MUMBER = IMAGE_MUMBER): batch_x = np.zeros([batch_size, IMAGE_HEIGHT * IMAGE_WIDTH]) batch_y = np.zeros([batch_size, 1 * CHAR_SET_LEN]) def get_captcha_text_and_image(i): image_num = i label = labels[image_num] image_path = images[image_num] captcha_image = Image.open(image_path) captcha_image = np.array(captcha_image) return label, captcha_image for i in range(batch_size): text, image = get_captcha_text_and_image(random.randint(0, IMAGE_MUMBER - 1)) image = convert2gray(image) batch_x[i, :] = image.flatten() / 255 # (image.flatten()-128)/128 mean为0 batch_y[i, :] = text2vec(text) return batch_x, batch_y# 计算准确率def compute_accuracy(v_xs, v_ys, sess): # 传入测试样本和对应的label global prediction y_pre = sess.run(prediction, feed_dict=&#123;xs: v_xs, keep_prob: 1&#125;) correct_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(v_ys, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) result = sess.run(accuracy, feed_dict=&#123;xs: v_xs, ys: v_ys, keep_prob: 1&#125;) return resultprediction = code_cnn()def train_code_cnn(image_paths, labels): # 定义网络 global prediction # 计算loss cross_entropy cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1])) train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy) sess = tf.Session() # 初始化variable init = tf.global_variables_initializer() sess.run(init) for epoch in range(EPOCH): # 每个epoch for each in range(int(IMAGE_MUMBER / BATCH_SIZE)): batch_x, batch_y = get_next_batch(BATCH_SIZE, each, image_paths, labels) _, loss_ = sess.run([train_step, cross_entropy] , feed_dict=&#123;xs: batch_x, ys: batch_y, keep_prob: 0.5&#125;) print("epoch: %d iter: %d/%d loss: %f" % (epoch + 1, BATCH_SIZE * each, IMAGE_MUMBER, loss_)) # 训练样本测试准确率 test_iamge_path = "data/image/test/" test_labels_path = "data/code_test_text.txt" test_image_paths, test_labels = \ get_image_path_labels(test_iamge_path, test_labels_path, 200) batch_x_test, batch_y_test = \ get_random_batch(BATCH_SIZE, test_image_paths, test_labels,200) accuracy_test = compute_accuracy(batch_x_test, batch_y_test, sess) print("测试样本测试 epoch: %d acc: %f" % (epoch + 1, accuracy_test)) batch_x_test, batch_y_test = get_random_batch(BATCH_SIZE, image_paths, labels) accuracy = compute_accuracy(batch_x_test, batch_y_test, sess) print("训练样本测试 epoch: %d acc: %f" % (epoch + 1, accuracy))# 根据路径得到文本的内容def getStrContent(path): return open(path, 'r', encoding="utf-8").read()# 返回 训练样本路径的list 和 对应的标签用来以后训练def get_image_path_labels(IMAGE_PATH=IMAGE_PATH, LABEL_PATH=LABEL_PATH, IMAGE_MUMBER=IMAGE_MUMBER): image_path = IMAGE_PATH label_path = LABEL_PATH image_paths = [] for each in range(IMAGE_MUMBER): image_paths.append(image_path + str(each) + ".jpg") string = getStrContent(label_path) labels = string.split("#") return image_paths, labelsdef main(): # 得到训练样本路径list和标签的list image_paths, labels = get_image_path_labels() train_code_cnn(image_paths, labels)if __name__ == '__main__': main()]]></content>
      <categories>
        <category>deeplearn</category>
      </categories>
      <tags>
        <tag>MNIST</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java操作文本文件]]></title>
    <url>%2F2017%2F12%2F05%2Fjava%E8%AF%BB%E5%86%99%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[java的操作相对python繁琐一点，所以这里把一些常用的记录下来。 java 操作文本文件 1.判断文件夹是不是存在，不存在创建1234567String path = "/home/tianchaoxiong/LinuxData/data/verifies/";File file =new File(path); //如果文件夹不存在则创建 if (!file.exists()) &#123; file.mkdir(); &#125; 2.判断文件是不是存在，不存在创建12345678910String fileName = "ceshi.txt";File filename = new File(path+fileName); if(!file.exists()) &#123; try &#123; file.createNewFile();//不存在直接创建 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; 3.java 从指定路径中读文本文件12345678910111213141516171819202122232425262728293031323334353637383940414243import java.io.BufferedReader;import java.io.BufferedWriter;import java.io.File;import java.io.FileInputStream;import java.io.FileWriter;import java.io.IOException;import java.io.InputStream;import java.io.InputStreamReader;public class OptTxt &#123; public static void main(String[] args) throws IOException &#123; readTxt(); // saveTxt(); &#125; private static void readTxt() throws IOException &#123; // 可为文本相对路劲，可以文件夹绝对路径 String path3 = "ceshi.txt"; // StringBuffer用来接收解析完了之后的文本内容 StringBuffer sb = new StringBuffer(); // 自定义函数读文本 返回一个StringBuffer readToBuffer(sb, path3); // StringBuffer转为String显示 String resultString = sb.toString(); System.out.println(resultString); &#125; public static void readToBuffer(StringBuffer buffer, String filePath) throws IOException &#123; InputStream is = new FileInputStream(filePath); String line; // 用来保存每行读取的内容 BufferedReader reader = new BufferedReader(new InputStreamReader(is)); line = reader.readLine(); // 读取第一行 while (line != null) &#123; // 如果 line 为空说明读完了 buffer.append(line); // 将读到的内容添加到 buffer 中 buffer.append("\n"); // 添加换行符 line = reader.readLine(); // 读取下一行 &#125; reader.close(); is.close(); &#125;&#125; 4.把txt写入指定路径的文件文件中。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import java.io.BufferedReader;import java.io.BufferedWriter;import java.io.File;import java.io.FileInputStream;import java.io.FileWriter;import java.io.IOException;import java.io.InputStream;import java.io.InputStreamReader;public class OptTxt &#123; public static void main(String[] args) throws IOException &#123; // readTxt(); saveTxt(); &#125; private static void saveTxt() throws IOException &#123; // 可为文本相对路劲，可以文件夹绝对路径 String path = "/home/tianchaoxiong/LinuxData/data/verifies/"; File file = new File(path); // 如果文件夹不存在则创建 if (!file.exists()) &#123; file.mkdir(); &#125; // 如果文件不存在则创建 String fileName = "ceshi.txt"; File filename = new File(path + fileName); if (!file.exists()) &#123; try &#123; file.createNewFile();// 不存在直接创建 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; // 写入内容 String content = "This is the content to write into file"; writeToBuffer(content, filename); &#125; private static void writeToBuffer(String content, File filename) &#123; try &#123; FileWriter fw = new FileWriter(filename.getAbsoluteFile()); BufferedWriter bw = new BufferedWriter(fw); bw.write(content); bw.close(); System.out.println("success"); &#125; catch (IOException e) &#123; System.out.println("fail"); e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>io操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在无界面的centos安装matlab]]></title>
    <url>%2F2017%2F12%2F05%2Fcenos%E5%AE%89%E8%A3%85matlab%2F</url>
    <content type="text"><![CDATA[在无界面的centos安装matlab 本文安装的是 matlab R2015b 大概7.9个G左右. 下载链接 连接密码(ik4r) 使用的文件和其他linux有界面版本相同 安装之后的效果: 1. 挂载iso文件.因为下载好的文件中包含三个有用的文件 R2015b_glnxa64.iso (安装文件 需要挂载) ShortCut_Linux.zip () Matlab 2015b Linux64 Crack.rar(激活文件) 123挂载指令$ sudo mkdir /media/matlab$ sudo mount -o loop R2015b_glnxa64.iso /media/matlab 现在在/media/matlab中就能看到安装命令 2. 安装如果直接使用 sudo ./install就会出现两行文字然后直接finish.这时候就说明没有安装成功. 两行字的意思是 1. 可以安装桌面环境重新安装, 2.可以使用静态安装,不用图形环境 如果需要图形环境的话可以使用VNC viewer如果使用这个就和再ubuntu上使用是一样的提供用户界面,不过这个时候还需要再centos上安装 VNC server,我没有测试,这里有参考文章 我使用的是静态安装无界面的,那么程序中若使用到窗口等控件,可能就不能用. 安装指令 1sudo ./install -fileInstallationKey 09806-07443-53955-64350-21751-41297 -agreeToLicense yes -mode silent -activationPropertiesFile /home/jzhang/program/Matlab\ 2015b\ Linux64\ Crack//license_standalone.lic 详细解释是这样 1sudo ./install -destinationFolder 安装位置 -fileInstallationKey 秘钥(如果版本一样可以使用我的这个,如果不一样看看你破解文件中的readme.txt) -agreeToLicense yes -mode silent -activationPropertiesFile (破解文件中license_standalone.lic的位置) 执行一分钟 就会有finish提示 我的提示是这样.123456789101112131415&gt; 1。以下产品需要安装支持的编译器:&gt; Stateflow 8.6&gt; Simulink Coder 8.9&gt; MATLAB Coder 3.0&gt; Simulink Test 1.1&gt; 2。Simulink 需要使用 C 编译器以实现仿真加速、模型引用和 MATLAB 函数块功能。建议在您的计算机上安装支持的编译器。&gt; 3。要加快以下产品的计算速度，需要安装支持的编译器:&gt; SimBiology 5.3&gt; Fixed-Point Designer 5.1&gt; 4。此安装完成后，应按照从 www.mathworks.com/distconfig 获取的说明中所述继续配置 MATLAB Distributed Computing Server。&gt; 5。MATLAB Compiler SDK 6.1 要求安装以下程序:&gt; ● 支持的编译器，用于创建 C 和 C++ 共享库&gt; ● Java JDK，用于创建 Java 包&gt; (十一月 29, 2017 09:41:09) Exiting with status 0&gt; (十一月 29, 2017 09:41:12) End - Successful. 如此便是安装成功 如果你自定义路径则安装了你的自定义路径,如果没就安装到了/usr/local/MATLAB/R2015b 这个时候你就可以测试 是不是安装成功了. 进入 bin执行 3. 安装破解文件激活 把破解文件中/Matlab 2015b Linux64 Crack/R2015b/bin/glnxa64下面的三个文件全部拷贝到安装文件对应的位置 1sudo cp /home/jzhang/matlab_install_program/Matlab 2015b Linux64 Crack/R2015b/bin/glnxa64/* /usr/local/MATLAB/R2015b/bin/glnxa64/ 拷贝licenses文件 12mkdir licensessudo cp /home/jzhang/matlab_install_program/Matlab 2015b Linux64 Crack/license_standalone.lic /usr/local/MATLAB/R2015b/licenses/ 4. 建立全局软连接 卸载iso现在的matlab 只能再/usr/local/MATLAB/R2015b/bin下面运行,需要把他改为全局的使用软连接的方式 1sudo ln -s /usr/local/MATLAB/R2015b/bin/matlab /usr/local/bin/matlab 1sudo ln -s 原位置 /usr/local/bin/matlab 卸载 1sudo umount /media/matlab 参考目录 Matlab2016 linux安装 Linux Debian8 x64下安装Matlab 2015b VNC服务器安装]]></content>
      <categories>
        <category>软件安装</category>
      </categories>
      <tags>
        <tag>软件安装</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android-面部识别之一（SDK自带检测检测算法）]]></title>
    <url>%2F2017%2F12%2F05%2FAndroid-%E9%9D%A2%E9%83%A8%E8%AF%86%E5%88%AB%E4%B9%8B%E4%B8%80%EF%BC%88SDK%E8%87%AA%E5%B8%A6%E6%A3%80%E6%B5%8B%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%EF%BC%89%2F</url>
    <content type="text"><![CDATA[其实Android SDK从1.0版本中（API level 1）就已经集成了简单的人脸识别功能，通过调用FaceDetector 我们可以在Android平台上实现Bitmap人脸识别（包含多人脸）。 Tips： 自带的这个算法在检测上是存在很多的局限性的，是通过找图片中眼睛，返回眼睛的位置和两个眼睛之间的距离，从而可以粗略的计算出整个脸的大小。 局限性就是如果眼睛没有睁开就看不到眼睛。 实现的代码很简单就不做过多的解释 ，这里贴出检测的代码。 完整代码共享在文章最后的百度网盘。 先做一个简单的介绍 检测方案：通过查找人脸中的眼睛来标识人脸。可通过函数public float eyesDistance ()来获取两个眼睛的距离，可通过public void getMidPoint(PointF point)拿到两个眼睛中心的坐标。 bitmap检测的时候需要转换成RGB_565。文末详述。 1234FaceDetector faceDet = new FaceDetector(bitmap.getWidth(),bitmap.getHeight(), MAX_FACES); // 将人脸数据存储到facelist中 FaceDetector.Face[] faceList = new FaceDetector.Face[MAX_FACES]; faceDet.findFaces(bitmap, faceList); 第一二行 构造检测器，第三行声明FaceDetector.Face数组第四行检测。 最后通过canvas 进行绘制。 DetecteSDK检测类实现的功能是 传入一个 bitmap对象 返回一个检测完成绘制出面部的bitmap图像。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.centaur.testutil;//倒包import android.graphics.Bitmap;import android.graphics.Canvas;import android.graphics.Color;import android.graphics.Paint;import android.graphics.PointF;import android.graphics.RectF;import android.media.FaceDetector;import android.util.Log;public class DetecteSDK &#123; private static final String TAG = "FaceIdentify"; public Bitmap DetectionBitmap(Bitmap bitmap) &#123; Log.d(TAG, "开始检测"); // 检测前必须转化为RGB_565格式。文末有详述连接 bitmap = bitmap.copy(Bitmap.Config.RGB_565, true); // 设定最大可查的人脸数量 int MAX_FACES = 5; FaceDetector faceDet = new FaceDetector(bitmap.getWidth(), bitmap.getHeight(), MAX_FACES); // 将人脸数据存储到facelist中 FaceDetector.Face[] faceList = new FaceDetector.Face[MAX_FACES]; faceDet.findFaces(bitmap, faceList); // FaceDetector API文档我们发现，它查找人脸的原理是：找眼睛。 // 它返回的人脸数据face， // 通过调用public float eyesDistance ()， // public void getMidPoint(PointF point)， // 我们可以得到探测到的两眼间距，以及两眼中心点位置（MidPoint）。 // public float confidence () 可以返回该人脸数据的可信度(0~1)， // 这个值越大，该人脸数据的准确度也就越高。 RectF[] faceRects = new RectF[faceList.length]; for (int i = 0; i &lt; faceList.length; i++) &#123; FaceDetector.Face face = faceList[i]; if (face != null) &#123; Log.d(TAG, "标志位置"); PointF pf = new PointF(); face.getMidPoint(pf); // 这里的框，参数分别是：左上角的X,Y 右下角的X,Y // 也就是左上角（r.left,r.top），右下角( r.right,r.bottom)。 // 作为定位，确定这个框的格局。 RectF r = new RectF(); r.left = pf.x - face.eyesDistance() / 2; r.right = pf.x + face.eyesDistance() / 2; r.top = pf.y - face.eyesDistance() / 2; r.bottom = pf.y + face.eyesDistance() / 2; Log.d(TAG, r.toString()); faceRects[i] = r; // 画框:对原图进行处理，并在图上显示人脸框。 Canvas canvas = new Canvas(bitmap); Paint p = new Paint(); p.setAntiAlias(true); p.setStrokeWidth(4); p.setStyle(Paint.Style.STROKE); p.setColor(Color.RED); // 画一个圈圈 canvas.drawCircle(r.left, pf.y, 10, p); canvas.drawCircle(r.right, pf.y, 10, p); // 画框 canvas.drawRect(r, p); &#125; &#125; return bitmap; &#125;&#125; 百度网盘地址：链接：http://pan.baidu.com/s/1boYfhuB 密码：jgnh 以下为引用原理详述。Bitmap.Config.RGB_565详述。]]></content>
      <categories>
        <category>Android开发</category>
      </categories>
      <tags>
        <tag>面部识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐一个好用的图床：极简图床]]></title>
    <url>%2F2017%2F12%2F05%2F%E6%8E%A8%E8%8D%90%E5%9B%BE%E5%BA%8A%2F</url>
    <content type="text"><![CDATA[分享一个好用的图床工具 - 极简图床 应用场景：可能你经常会用markdown写文章，那么本文的图片如何添加连接呢？ 解决方案1 使用typora可以支持本地相对路径查看，缺点是内容如果拷贝到其他平台还需要重新更改，否则不能查看。 解决方案2 使用图床工具，第一次就用图片的网络地址，缺点是每次需要上传图片比较麻烦。 极简图床就是一款让上传非常方便的工具，他的作用就是一个桥梁，把你的图片和你要存储的位置绑定起来，优化整个流程，支持绑定的有微博，和七牛云。 配置都不难，就不做赘述 如果需要耐心根据提示走一遍就配置好了。 推荐理由 支持chrome插件，alt+2上传图片（上传本地图片），alt+1采集图片（采集网络图片上传）。 数据存储在微博，或者是七牛云。（本人使用的七牛云，可以绑定微博，使用微博做为存储，不过担心每次都发一个微博那不是尴尬了，没有测试） 免费]]></content>
      <categories>
        <category>share tools</category>
      </categories>
      <tags>
        <tag>markdown写作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pycharm-cv2-无法自动代码补全]]></title>
    <url>%2F2017%2F12%2F04%2Fpycharm-cv2-%E6%97%A0%E6%B3%95%E8%87%AA%E5%8A%A8%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8%2F</url>
    <content type="text"><![CDATA[再python中安装了opencv之后没有自动不全功能，可通过以下方式解决。 正常使用pip install opencv-python安装,可是使用,无代码提示. 解决方案:在安装目录site-packages中找到cv2(我电脑的安装路径/home/username/LinuxData/software/anacodna3/lib/python3.6/site-packages/cv2),修改其中__init__.py如下:1234#from . import cv2#sys.modules['cv2'] = cv2from .cv2 import *sys.modules['cv2'] = cv2 亲测可用,所以分享给大家.参考出处]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>open-cv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu-系统U盘中-文件出现小锁子]]></title>
    <url>%2F2017%2F12%2F04%2Fubuntu-%E7%B3%BB%E7%BB%9FU%E7%9B%98%E4%B8%AD-%E6%96%87%E4%BB%B6%E5%87%BA%E7%8E%B0%E5%B0%8F%E9%94%81%E5%AD%90%2F</url>
    <content type="text"><![CDATA[因为U盘的不正确插拔导致U盘中的所有文件图标上面都有一个小锁子，操作的时候显示位置错误，里面的文件都变成只读文件。 这是由于插拔的不正确导致驱动出问题，下面是修复的过程。 插入不有问题的U盘，输入sudo fdisk -l指令，查看磁盘信息。通过对比，很容易找到出错盘符的信息，U盘一般再最后一个，格式如果没有更改 一般是FAT32，也可通过大小辨认 查看挂载点 比如我的电脑 cd cd /media/tianchaoxiong/ cd /media/你的主机名 下载挂载点 umount /media/tianchaoxiong/disk 修复挂载点 sudo dosfsck -v -a /dev/sdc1期间不要拔掉U盘 修复完成 之后重新插入，U盘使用正常。]]></content>
      <categories>
        <category>ubuntu系统</category>
      </categories>
      <tags>
        <tag>ubuntu问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu中非常好用的指令]]></title>
    <url>%2F2017%2F12%2F04%2Fubuntu%E4%B8%AD%E9%9D%9E%E5%B8%B8%E5%A5%BD%E7%94%A8%E7%9A%84%E6%8C%87%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[本人记性不好，碰到一些特好的指令的时候总是记不住，所以特意用这个帖子来记下来，顺便做一个分享。 持续更新。。。 记录一些功能非常强大的指令1.rename 批量更改文件名 解释：假如一个文件夹中有foo1 和foo2 现在想同事改名为foox1 和foox2 ubuntu上的指令是：rename &#39;s/foo/foox/&#39; * rename 操作符 ‘s/‘正则 原始字符/ 替换成的字符/ 表示对文件夹下所有操作 1234569_captcha generated.png #原始名称 批量9.png # 目标名称方法一：rename '_captcha generated' '' *.png （debian-based的系统下，rename没有上面那种用法 cenos可行 ubuntu不行）方法二： rename "s/_captcha*//" *.png rename "s/ generated//" *.png 两个例子1234ename 'y/A-Z/a-z/' * //大写转小写rename "s/png/jpg/" *" * //把.png 后缀的改成 .jpg后缀rename "s/$//.txt/" * //把所有的文件名都以txt结尾rename "s//.txt//" * //把所有以.txt结尾的文件名的.txt删掉 2. du 查看大小命令 du -hl 指定文件 查看指定文件的大小 du -hl -s 指定文件夹 查看指定文件夹的大小 -s表示不向下递归 du -hl --max-depth=1 指定文件夹 查看指定文件夹下一层深度的文件的大小]]></content>
      <categories>
        <category>ubuntu系统</category>
      </categories>
      <tags>
        <tag>linux指令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim-操作指令-适用于-Pycharm-和类似软件，Chrome浏览器。]]></title>
    <url>%2F2017%2F12%2F04%2Fvim-%E6%93%8D%E4%BD%9C%E6%8C%87%E4%BB%A4-%E9%80%82%E7%94%A8%E4%BA%8E-Pycharm-%E5%92%8C%E7%B1%BB%E4%BC%BC%E8%BD%AF%E4%BB%B6%EF%BC%8CChrome%E6%B5%8F%E8%A7%88%E5%99%A8%E3%80%82%2F</url>
    <content type="text"><![CDATA[每个程序员都有一个全键盘操作的梦，，， 使用vim编辑不仅方便高效，还可以摆脱鼠标,全键盘操作。。。摆脱鼠标，装逼开始。。。 以下指令在pycharm 安装 IdeaVim插件 之后都测试过，都能很好的高效的运行。chrome内核浏览器 安装Vimium插件之后，浏览网页的时候，也可以高效的运行各种指令。两者指令基本类似，Vimium多了一下浏览器使用的快捷键，文末有列出。 三种模式 Normail Mode(命令模式） Insert Mode(输入模式) Visual Mode（视图模式）Normail Mode作为其他两种模式之间的桥梁，通过esc回到Normail Mode模式，如下图。 输入命令 i 光标左侧插入输入 I 跳到行首输入 a 光标右侧插入输入 A 跳到行尾输入 o 光标所在行的下一行新建一行，位于行首 O 光标所在行的上一行新建一行，位于行首 退出命令 :wq 保存文件退出VI :w 保存文件不退出VI :q 退出VI q! 不保存文件退出 ZZ 保存文件退出 文件修改 x 删除光标所在位置的字符 dd 删除一行 u 撤销最近的修改 U 撤销对当前行所做的所有修改 r 替换光标位置上的一个字符 R 替换光标开始的一行,esc退出。 . 重复上一次的修改 光标移动指令 h 左移动一个字 j 下移动一行 k 上移动一行 l 右移动一个字 w 右移动一个词语 b 左移动一个词语 e 光标移动到字尾 0 移动到行的最前 粘贴和复制 dd 删除 存到缓冲区 yy 复制 存到缓冲区 P 光标上一行恢复 p 光标下一行恢复 chrome的插件 Vimium 可以通过 shift+/ 调出帮助自己看，图我就不贴了，非常实用。]]></content>
      <categories>
        <category>share tools</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow学习之---CNN识别MNIST]]></title>
    <url>%2F2017%2F12%2F04%2Ftensorflow%E5%AD%A6%E4%B9%A0%E4%B9%8B---CNN%E8%AF%86%E5%88%ABMNIST%2F</url>
    <content type="text"><![CDATA[本文只通过tensorflow搭建cnn网络来识别MNIST的手写字符。 如果您已经掌握了这个 可以看我的另一篇博文tensorflow学习之–构建自己的图片数据，用cnn网络进行识别 TensorFlow TensorFlow™ 是一个使用数据流图进行数值计算的开源软件库。图中的节点代表数学运算， 而图中的边则代表在这些节点之间传递的多维数组（张量）。这种灵活的架构可让您使用一个 API 将计算工作部署到桌面设备、服务器或者移动设备中的一个或多个 CPU 或 GPU。 TensorFlow 最初是由 Google 机器智能研究部门的 Google Brain 团队中的研究人员和工程师开发的，用于进行机器学习和深度神经网络研究， 但它是一个非常基础的系统，因此也可以应用于众多其他领域。–摘自tensorflow.google.cn 总的来说： tensorflow是现在最流行的神经网络开发框架之一， github上现存开源代码最多的神经网络开发框架之一， 背后也有google团队支持，所以如果你是一个神经网络的研究者，是必须掌握tensorflow的.tensorflow的教程网上比较多,下面我列举几个。 官网的入门Tutorials 极客学院TensorFlow 官方文档中文版 极客学院中文文档下载地址MNIST再编程的时候我们的一个程序通常都是那句伟大的问候hello world!不过在tensorflow的学习中，就没有hello tensorflow!了，取而代之的就是MNIST手写数字的识别。简单的说MNIST是一个封装好书写数字的图片的一个数字集合。每个图片对应一个标签，其中包含5000个训练图片和训练标签还有1000个测试图片和测试标签。我简单的拿出来四个显示如下图： 再代码中可通过123from tensorflow.examples.tutorials.mnist import input_data# 准备数据mnist = input_data.read_data_sets('MNIST_data', one_hot=True) 自动的进行下载，下载之后再代码同级目录MNIST_data中就会多出四个文件 t10k-images-idx3-ubyte.gz t10k-labels-idx1-ubyte.gz train-images-idx3-ubyte.gz train-labels-idx1-ubyte.gz 这便是下载好的MNIST数据。那么下面我们将会用训练50000的数据去监督训练，然后10000个进行测试。 CNNcnn的基础这里有一篇很好的博文，他的全系列都是很棒的，推荐阅读，这里我就不介绍了，要了解的话移步他的博客。零基础入门深度学习(4) - 卷积神经网络 实现过程如下代码是通过构建CNN来识别MNIST数据的过程代码中大部分我都进行了注释，如果文章中哪里说的不清晰请再评论中留言，如果哪里说的有问题，欢迎指正。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data# MNIST再tensorflow中已经封装好了# mnist.test.images通过这种方式直接取出来就是tensor的形式，方便调用# 下一篇博文 会用自己的数据进行识别# 准备数据mnist = input_data.read_data_sets('MNIST_data', one_hot=True)# 通过上面的一句就可以直接下载到代码文件同级的MNIST_data文件夹之下，# 如果已经下载了默认就会跳过# 计算准确率 在测试的时候会用到def compute_accuracy(v_xs, v_ys): # 传入测试样本和对应的label global prediction #应为是个全局变量，在使用之前需要引用。 # 得到预测 y_pre = sess.run(prediction, feed_dict=&#123;xs: v_xs, keep_prob: 1&#125;) # tf.argmax（～，0或1）返回行或者列中最大数的下表如下所示 """ 小栗子 test = np.array([[1, 2, 3], [2, 3, 4], [5, 4, 3], [8, 7, 2]]) np.argmax(test, 0) ＃输出：array([3, 3, 1] np.argmax(test, 1) ＃输出：array([2, 2, 0, 0] """ correct_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(v_ys, 1)) # tf.cast 此函数是类型转换函数 accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) result = sess.run(accuracy, feed_dict=&#123;xs: v_xs, ys: v_ys, keep_prob: 1&#125;) return result# 计算weightdef weigth_variable(shape): # stddev : 正态分布的标准差 initial = tf.truncated_normal(shape, stddev=0.1) # 截断正态分布 return tf.Variable(initial)# 计算biasesdef bias_varibale(shape): # stddev : 正态分布的标准差 initial = tf.constant(0.1, shape=shape) return tf.Variable(initial)# 计算卷积def conv2d(x, W): # stride [1, x_movement, y_movement, 1] # tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None) return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')# 定义池化def max_pool_2x2(x): return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')# 定placeholderxs = tf.placeholder(tf.float32, [None, 784]) / 255.ys = tf.placeholder(tf.float32, [None, 10])keep_prob = tf.placeholder(tf.float32) # 用来处理过度拟合x_image = tf.reshape(xs, [-1, 28, 28, 1])# 定义第一层W_conv1 = weigth_variable([5, 5, 1, 32])b_conv1 = weigth_variable([32])# 卷积h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # 28*28*32# 池化h_pool1 = max_pool_2x2(h_conv1) # 14*14*32# 定义第二层W_conv2 = weigth_variable((5, 5, 32, 64))b_conv2 = weigth_variable([64])# 卷积h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # 14*14*64# 池化h_pool2 = max_pool_2x2(h_conv2) # 7*7*64# 定义第三层全连接层W_fc1 = weigth_variable([7 * 7 * 64, 1024]) #如果需要更改图片尺寸需要注意这里 7 这个是通过卷积和池化算出来的。b_fc1 = bias_varibale([1024])# [n_samples, 7, 7, 64] -&gt;&gt; [n_samples, 7*7*64]h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) # 防止过度拟合# 定义第四层全连接层W_fc2 = weigth_variable([1024, 10])b_fc2 = bias_varibale([10])prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)# 计算loss cross_entropycross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1]))# 梯度下降优化train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)sess = tf.Session()# 初始化variableinit = tf.global_variables_initializer()sess.run(init)# 训练ENPOCE = 1000for epoce in range(ENPOCE): batch_xs, batch_ys = mnist.train.next_batch(100) sess.run(train_step, feed_dict=&#123;xs: batch_xs, ys: batch_ys, keep_prob: 0.5&#125;) if epoce % 50 == 0: accuracy = compute_accuracy( mnist.test.images[:1000], mnist.test.labels[:1000]) print("epoch: %d acc: %f" % (epoch + 1, accuracy))]]></content>
      <categories>
        <category>deeplearn</category>
      </categories>
      <tags>
        <tag>MNIST</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我会经常在这个地址下面共享自己保存的几本书]]></title>
    <url>%2F2017%2F12%2F04%2F%E6%88%91%E4%BC%9A%E7%BB%8F%E5%B8%B8%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%9C%B0%E5%9D%80%E4%B8%8B%E9%9D%A2%E5%85%B1%E4%BA%AB%E8%87%AA%E5%B7%B1%E4%BF%9D%E5%AD%98%E7%9A%84%E5%87%A0%E6%9C%AC%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[github地址 Android开发 第一行代码-Android（第一版） 第一行代码-Android（第二版） Android 逆向 Android安全攻防权威指南 Android软件安全与逆向分析 java学习 Head+First+Java.第二版.中文完整高清版 Java编程思想第四版完整中文高清版 python开发 Python3程序开发指南.第二版 深入 Python 3 中文版 廖雪峰官方博客]]></content>
      <categories>
        <category>share tools</category>
      </categories>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习初学者的资源分享]]></title>
    <url>%2F2017%2F12%2F04%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%88%9D%E5%AD%A6%E8%80%85%E7%9A%84%E8%B5%84%E6%BA%90%E5%88%86%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[我是一个深度学习的初学者，这里把自己学习中的一些觉得比较好的东西做一个分享。 python 基础推荐 廖雪峰python教程，可做先做了解然后作为工具去查，python很好写，从代码的角度入门很快。 深度学习理论基础零基础入门深度学习：不多的几课，有相应的数学推倒，这是到现在看过最好理论基础。 相关书籍Deep Learning：这本书在网上的评价很高，很多大牛也有推荐，作者之一是深度学习中很有分量的专家。英文版中文版 平台学习tensorflow 周沫凡 Mofan Zhou个人博客:作者再知乎和个人博客上分享了很多入门的教程，通过tensorflow搭建各种最常见的网络，简单易懂，很推荐。 tensorflow分析的tensorflow官方入门文档：可在线学习，也可以下载下来看，建议先看周沫凡的教程，再看这个会容易很多。 pytorch 周沫凡 Mofan Zhou个人博客还是推荐沫凡的个人博客。 相关视频推荐吴恩达再网易云课堂上面的深度学习工程师 还很片面，我自己也会不断补充，希望大家看到也可以补充。]]></content>
      <categories>
        <category>deeplearn</category>
      </categories>
      <tags>
        <tag>deeplearn</tag>
      </tags>
  </entry>
</search>
